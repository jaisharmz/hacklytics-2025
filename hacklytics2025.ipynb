{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "82AXI8OlU8kB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :]\n",
        "\n",
        "# class TransformerAutoencoder(nn.Module):\n",
        "#     def __init__(self, time_steps, d_model=128, nhead=4, num_layers=3, latent_dim=64, dim_feedforward=256, dropout=0.1):\n",
        "#         super().__init__()\n",
        "#         self.input_proj = nn.Linear(1, d_model)  # Project feature dim (1) to d_model\n",
        "#         self.pos_encoder = PositionalEncoding(d_model, max_len=time_steps)\n",
        "\n",
        "#         # Transformer Encoder\n",
        "#         encoder_layer = nn.TransformerEncoderLayer(\n",
        "#             d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout,\n",
        "#             activation=\"gelu\", batch_first=True, norm_first=True\n",
        "#         )\n",
        "#         self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "#         # Latent Space Projection\n",
        "#         self.latent_proj = nn.Linear(d_model, latent_dim)\n",
        "\n",
        "#         # Transformer Decoder\n",
        "#         decoder_layer = nn.TransformerDecoderLayer(\n",
        "#             d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout,\n",
        "#             activation=\"gelu\", batch_first=True, norm_first=True\n",
        "#         )\n",
        "#         self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
        "\n",
        "#         # Output Projection\n",
        "#         self.output_proj = nn.Linear(d_model, 1)\n",
        "\n",
        "#         # Residual Layer Norm\n",
        "#         self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # x: [batch_size, num_features=1, time_steps]\n",
        "#         x = x.permute(0, 2, 1)  # [batch_size, time_steps, num_features]\n",
        "#         x = self.input_proj(x)\n",
        "#         x = self.pos_encoder(x)\n",
        "\n",
        "#         # Encoder Forward Pass\n",
        "#         enc_output = self.encoder(x)\n",
        "#         enc_output = self.layer_norm(enc_output)\n",
        "\n",
        "#         # Latent Space Representation\n",
        "#         latent = self.latent_proj(enc_output)\n",
        "\n",
        "#         # Decoder Forward Pass (Reconstruction)\n",
        "#         dec_output = self.decoder(enc_output, enc_output)  # Using encoded input as target for reconstruction\n",
        "#         dec_output = self.layer_norm(dec_output)\n",
        "\n",
        "#         # Output Projection\n",
        "#         out = self.output_proj(dec_output)  # Shape: [batch_size, time_steps, 1]\n",
        "#         out = out.permute(0, 2, 1)  # Back to [batch_size, 1, time_steps]\n",
        "\n",
        "#         return out, latent  # Returning both the reconstruction and latent space"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerAutoencoder(nn.Module):\n",
        "    def __init__(self, time_steps, d_model=128, nhead=4, num_layers=3, latent_dim=64, dim_feedforward=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(1, d_model)  # Project feature dim (1) to d_model\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=time_steps)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout,\n",
        "            activation=\"gelu\", batch_first=True, norm_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Latent Space Projection (Global Pooling to get a single vector)\n",
        "        self.latent_proj = nn.Linear(d_model, latent_dim)  # Reduce d_model â†’ latent_dim\n",
        "        self.reverse_proj = nn.Linear(latent_dim, d_model)\n",
        "        self.latent_norm = nn.LayerNorm(latent_dim)  # Normalize latent space\n",
        "\n",
        "        # Transformer Decoder\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout,\n",
        "            activation=\"gelu\", batch_first=True, norm_first=True\n",
        "        )\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Output Projection\n",
        "        self.output_proj = nn.Linear(d_model, 1)\n",
        "\n",
        "        # Ensure normalization for correct dimensions\n",
        "        self.encoder_norm = nn.LayerNorm(d_model)\n",
        "        self.decoder_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [batch_size, num_features=1, time_steps]\n",
        "        \"\"\"\n",
        "        x = x.permute(0, 2, 1)  # Convert to [batch_size, time_steps, num_features]\n",
        "        x = self.input_proj(x)  # Project input to d_model\n",
        "        print(x.shape)\n",
        "        x = self.pos_encoder(x)\n",
        "        print(x.shape)\n",
        "        # Encoder Forward Pass\n",
        "        enc_output = self.encoder(x)  # Shape: [batch_size, time_steps, d_model]\n",
        "        print(enc_output.shape)\n",
        "        enc_output = self.encoder_norm(enc_output)  # Apply LayerNorm\n",
        "        print(enc_output.shape)\n",
        "        # Global Mean Pooling to get a single latent vector\n",
        "        latent = enc_output.mean(dim=1, keepdim=True)  # Shape: [batch_size, 1, d_model]\n",
        "        print(latent.shape)\n",
        "        latent = self.latent_proj(latent)  # Shape: [batch_size, 1, latent_dim]\n",
        "        print(latent.shape)\n",
        "        latent = self.latent_norm(latent)  # Normalize latent space\n",
        "        print(latent.shape)\n",
        "        latent = self.reverse_proj(latent)\n",
        "        print(latent.shape)\n",
        "        # Expand latent representation back to sequence length\n",
        "        repeated_latent = latent.repeat(1, x.shape[1], 1)  # Shape: [batch_size, time_steps, latent_dim]\n",
        "        print(repeated_latent.shape)\n",
        "        # Decoder Forward Pass\n",
        "        dec_output = self.decoder(repeated_latent, enc_output)  # Shape: [batch_size, time_steps, d_model]\n",
        "        print(dec_output.shape)\n",
        "        dec_output = self.decoder_norm(dec_output)  # Apply LayerNorm\n",
        "        print(dec_output.shape)\n",
        "        # Output Projection\n",
        "        out = self.output_proj(dec_output)  # Shape: [batch_size, time_steps, 1]\n",
        "        out = out.permute(0, 2, 1)  # Back to [batch_size, 1, time_steps]\n",
        "\n",
        "        return out, latent.squeeze(1)  # Returning [batch, 1, seq_len] & [batch, latent_dim]\n"
      ],
      "metadata": {
        "id": "Qwx3UwHAiCmJ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WbPE4VkVNJU",
        "outputId": "4cd76a01-6e07-407b-d25c-71ca84bcee01"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rus1000 = pd.read_csv(\"/content/RUSSELL_1000_5y.csv\")\n",
        "spy500 = pd.read_csv(\"/content/SPY_500_5y.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAunPm3IVvn6",
        "outputId": "7c907ff9-2fb5-4050-ed85-c2d0676f13a7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-65-7ea928f6593c>:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  rus1000 = pd.read_csv(\"/content/RUSSELL_1000_5y.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = spy500.iloc[2:,1:].dropna(axis=1).T.astype(float)\n",
        "X = X / X.iloc[:,0].values.reshape(488, 1)\n",
        "X_t, X_v = train_test_split(X.values, test_size=0.3, random_state=0)\n",
        "X_t = X_t.reshape(X_t.shape[0], 1, X_t.shape[-1])\n",
        "X_v = X_v.reshape(X_v.shape[0], 1, X_v.shape[-1])"
      ],
      "metadata": {
        "id": "Erw92nReV2M6"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerAutoencoder(X_t.shape[1]).to(device)"
      ],
      "metadata": {
        "id": "z00rd8jBVFeJ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.zeros(32,1,1000).to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJo8eJ66jEHy",
        "outputId": "80950b52-0158-4c73-ea86-52be56e63353"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1000, 128])\n",
            "torch.Size([32, 1000, 128])\n",
            "torch.Size([32, 1000, 128])\n",
            "torch.Size([32, 1000, 128])\n",
            "torch.Size([32, 1, 128])\n",
            "torch.Size([32, 1, 64])\n",
            "torch.Size([32, 1, 64])\n",
            "FACK\n",
            "FUCK\n",
            "torch.Size([32, 1, 128])\n",
            "torch.Size([32, 1000, 128])\n",
            "torch.Size([32, 1000, 128])\n",
            "torch.Size([32, 1000, 128])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.7368, 0.6719, 0.6960,  ..., 0.8009, 0.7045, 0.7418]],\n",
              " \n",
              "         [[0.7056, 0.6783, 0.7427,  ..., 0.7349, 0.7295, 0.6364]],\n",
              " \n",
              "         [[0.5686, 0.7441, 0.8402,  ..., 0.7857, 0.7086, 0.6548]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.4908, 0.8691, 0.9567,  ..., 0.6676, 0.8680, 0.8598]],\n",
              " \n",
              "         [[0.8694, 0.7959, 0.6559,  ..., 0.8610, 0.6839, 0.5189]],\n",
              " \n",
              "         [[0.6788, 0.5521, 0.7811,  ..., 0.5856, 0.5474, 0.8048]]],\n",
              "        device='cuda:0', grad_fn=<PermuteBackward0>),\n",
              " tensor([[-0.5396, -0.4193, -0.6710,  ..., -0.1164, -0.5929,  0.0811],\n",
              "         [-0.5441, -0.4238, -0.6725,  ..., -0.1140, -0.5914,  0.0843],\n",
              "         [-0.5365, -0.4217, -0.6709,  ..., -0.1152, -0.5937,  0.0880],\n",
              "         ...,\n",
              "         [-0.5409, -0.4249, -0.6760,  ..., -0.1258, -0.5924,  0.0881],\n",
              "         [-0.5269, -0.4281, -0.6729,  ..., -0.1094, -0.5896,  0.0950],\n",
              "         [-0.5364, -0.4177, -0.6704,  ..., -0.1149, -0.5875,  0.0920]],\n",
              "        device='cuda:0', grad_fn=<SqueezeBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_t, dtype=torch.float32))\n",
        "val_dataset = TensorDataset(torch.tensor(X_v, dtype=torch.float32))\n",
        "all_dataset = TensorDataset(torch.tensor(X.values.reshape(X.shape[0], 1, X.shape[-1]), dtype=torch.float32))\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "all_loader = DataLoader(all_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "P7ly3G0aWjBS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_autoencoder(model, train_loader, val_loader, num_epochs=50, lr=1e-4, device=\"cuda\"):\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for (batch, ) in train_loader:\n",
        "            x = batch.to(device)  # Move batch to GPU/CPU\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = model(x)  # Forward pass\n",
        "            loss = criterion(outputs, x)  # Compare to original input\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Compute average training loss\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for (batch, ) in val_loader:\n",
        "                x = batch.to(device)\n",
        "                outputs, _ = model(x)\n",
        "                loss = criterion(outputs, x)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        # Print epoch losses\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "kiTbWJ0LXHRu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = train_autoencoder(model, train_loader, val_loader, num_epochs=50, lr=1e-4, device=device)"
      ],
      "metadata": {
        "id": "GAkfXX9dXlZL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_temp = next(iter(val_loader))[0].to(device)\n",
        "# outputs, latent = model(X_temp)"
      ],
      "metadata": {
        "id": "3HbJ5KNFYJRq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.CosineSimilarity(dim=2)(X_temp, outputs)"
      ],
      "metadata": {
        "id": "IOQKZ8gaaV0K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.linalg.norm(X_temp), torch.linalg.norm(outputs)"
      ],
      "metadata": {
        "id": "o2MjPkcHauKU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model.state_dict(), \"model.pth\")\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3XDfoqMbVF8",
        "outputId": "89a7e43a-fdb6-4f7b-88f7-dee124aa0840"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-3b6ab60d012f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"model.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_t.shape"
      ],
      "metadata": {
        "id": "AEmJi7CcdI92"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "latents = []\n",
        "with torch.no_grad():\n",
        "    for (batch, ) in all_loader:\n",
        "        x = batch.to(device)\n",
        "        output, latent = model(x)\n",
        "        print(latent.shape)\n",
        "        latents.append(latent.cpu().detach().numpy())\n",
        "latents = np.concatenate(latents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "WubdjEG4c3m8",
        "outputId": "365abe8a-09d7-42ec-e6d1-2500102dcf91"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([32, 1257, 64])\n",
            "torch.Size([8, 1257, 64])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e5e6823aea52>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlatents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "9NHbGNbqcAiX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latents.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtIea5cxgHLc",
        "outputId": "9332ef4a-1576-4b62-918c-a1571d5c8ef0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(488, 1257, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "latents_transformed = pca.fit_transform(latents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "6ZTVewd8cPe2",
        "outputId": "f7b1f4e4-d446-4fc9-b45f-05ce0a7aa7d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with dim 3. PCA expected <= 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0d147bdd9d5d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlatents_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \"\"\"\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_is_centered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mU\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# The copy will happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# later, only if needed, once the solver negotiation below is done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m             )\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. PCA expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latents.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asusQxKtcWBv",
        "outputId": "75ac9824-3fde-4e13-922b-aecad52dec8a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(488, 1257, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgXIp75icXIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}